{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7fe6ee-f605-423b-affe-0fca21603e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "import codecs\n",
    "from indicnlp.tokenize import indic_tokenize \n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4889bd2c-a80f-475e-ba44-bc6ffe08de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"Eng_story.txt\",encoding='utf-8') as f:\n",
    "    Story = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cee3b6c-bbd1-48f3-bb0d-786557b52b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "States = indic_tokenize.trivial_tokenize(Story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4d849e-e423-4149-8f44-d7b98a7ae89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MarkovChain(states,number_of_words):\n",
    "    Graph = {}\n",
    "    for i in range(len(states)-number_of_words-1):\n",
    "        present_state, future_state = \"\",\"\"\n",
    "        for j in range(number_of_words):\n",
    "            present_state += states[i+j]+\" \"\n",
    "            future_state += states[i+j+number_of_words]+\" \"\n",
    "        present_state = present_state[:-1]\n",
    "        future_state = future_state[:-1]\n",
    "        if present_state not in Graph:\n",
    "            Graph[present_state] = {}\n",
    "            Graph[present_state][future_state] = 1\n",
    "        else:\n",
    "            if future_state in Graph[present_state]:\n",
    "                Graph[present_state][future_state] += 1\n",
    "            else:\n",
    "                Graph[present_state][future_state] = 1 \n",
    "    \n",
    "    for present_state,transition in Graph.items():\n",
    "        Total = sum(transition.values())\n",
    "        for state,count in transition.items():\n",
    "            Graph[present_state][state] = count/Total\n",
    "            \n",
    "    return Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b980cb2-e7bb-4b0a-9782-3a2fc01e65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition_states = MarkovChain(States,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489f0238-52f4-4a62-961f-5147f73e6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lines(Graph,start, limit=100):\n",
    "    n = 0\n",
    "    present_state = start\n",
    "    future_state = None\n",
    "    generated_lines = \"\"\n",
    "    generated_lines+=present_state+\" \"\n",
    "    while n<limit:\n",
    "        future_state = random.choices(list(Graph[present_state].keys()),\n",
    "                                    list(Graph[present_state].values()))\n",
    "        \n",
    "        present_state = future_state[0]\n",
    "        generated_lines+=present_state+\" \"\n",
    "        n+=1\n",
    "    return generated_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8f18d46-526d-420a-b31f-c09aab27cf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A soft and forth in bed , too , the Boy , Velveteen Rabbit to stay in a picnic , Velveteen Rabbit to Velveteen Rabbit was old . If the best , dear ! That walking doggie is missing . \\r\\n\\r\\nOne day the toy box . \" You can move when the Boy would hold Velveteen Rabbit was worn away . \\r\\n\\r\\nThen newer , brighter toys get loved , the Boy would hold Velveteen Rabbit lived in a button . But he was happy . â€\\r\\n\\r\\nOne day Nana , too . \\r\\n\\r\\nThen at last , flew open the Boy became sick '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lines(Transition_states,States[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
